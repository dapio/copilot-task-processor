# AI/ML Prompts Index - Quick Reference Guide

## üéØ **QUICK ACCESS PROMPTS**

### **üöÄ IMPLEMENTATION PROMPTS**

#### **New Feature Implementation**

```
CONTEXT: ThinkCode AI Platform - Implementing new feature
ROLE: Senior Full-Stack Architect with bulletproof patterns expertise

Follow this workflow:
1. Load core-standards.md for fundamental principles
2. Apply workflow-instructions.md phases 1-4
3. Use specialized-prompts/code-generation.md templates
4. Validate with quality-gates.md checklistes
5. Manage context per context-management.md strategies

MANDATORY REQUIREMENTS:
‚úÖ Result<T, E> pattern for all async operations
‚úÖ Comprehensive error handling with retry/fallback
‚úÖ Full accessibility compliance (WCAG 2.1 AA)
‚úÖ TypeScript strict mode
‚úÖ 80%+ test coverage
‚úÖ Mobile-first responsive design
‚úÖ Integration with MockDataService fallbacks
‚úÖ WorkflowService pattern usage
```

#### **Service Layer Creation**

```
APPLY: docs/ai-instructions/specialized-prompts/code-generation.md -> "API Service Creation"

BULLETPROOF PATTERN:
- Result<T, E> returns
- Zod validation schemas
- Automatic retry (3 attempts)
- Timeout handling (10s)
- MockDataService fallbacks
- WorkflowService integration
- 95%+ test coverage
- Comprehensive JSDoc
```

#### **React Component Creation**

```
APPLY: docs/ai-instructions/specialized-prompts/code-generation.md -> "React Component Creation"

ACCESSIBILITY FIRST:
- WCAG 2.1 AA compliance (100%)
- Full keyboard navigation
- Screen reader optimization
- ARIA labeling complete
- Mobile-responsive design
- Loading/error/empty states
- Performance optimization
```

### **üîß REFACTORING PROMPTS**

#### **Legacy Code Refactoring**

```
APPLY: docs/ai-instructions/specialized-prompts/refactoring-debugging.md -> "Service Layer Refactoring"

REFACTORING PROCESS:
1. Assessment: Analyze current patterns
2. Planning: Incremental change strategy
3. Implementation: Small, testable increments
4. Validation: Complete test suite + integration

TARGET: Bulletproof architecture compliance
```

#### **Accessibility Refactoring**

```
APPLY: docs/ai-instructions/specialized-prompts/refactoring-debugging.md -> "Component Refactoring for Accessibility"

AUDIT PROTOCOL:
1. axe-core scan
2. Keyboard navigation test
3. Screen reader compatibility
4. ARIA usage validation
5. Color contrast check

TARGET: 100% WCAG 2.1 AA compliance
```

### **üêõ DEBUGGING PROMPTS**

#### **Service Error Investigation**

```
APPLY: docs/ai-instructions/specialized-prompts/refactoring-debugging.md -> "Service Layer Error Investigation"

DEBUG PROTOCOL:
1. Error categorization
2. Evidence collection
3. Root cause analysis
4. Retry/fallback validation

OUTPUT: Actionable error resolution
```

#### **React Component Debugging**

```
APPLY: docs/ai-instructions/specialized-prompts/refactoring-debugging.md -> "React Component Debugging"

INVESTIGATION AREAS:
- State analysis
- Render cycle issues
- Event flow problems
- Performance bottlenecks
- Memory leaks
```

### **üß™ TESTING PROMPTS**

#### **Comprehensive Testing**

```
APPLY: docs/ai-instructions/specialized-prompts/code-generation.md -> "Comprehensive Component Testing"

COVERAGE REQUIREMENTS:
- Unit tests: All functionality
- Integration: Service-hook-component flow
- Accessibility: axe-core + manual testing
- Performance: Render optimization
- Edge cases: Error conditions

THRESHOLDS:
- Services: 95%+ coverage
- Hooks: 90%+ coverage
- Components: 85%+ coverage
```

### **üß† MICROSOFT EXPERT REVIEW PROMPTS**

#### **Initial Critical Analysis**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Base Persona Prompt"

MICROSOFT EXPERT MODE:
üî• Senior Principal Engineer at Microsoft
üî• 15+ years enterprise experience
üî• Zero tolerance for technical debt
üî• Authority: Final deployment approval

ANALYSIS PHASES:
1. Architecture Review (Result<T,E> patterns)
2. Code Quality Deep Dive (TypeScript excellence)
3. Security & Accessibility Audit (WCAG 2.1 AA)
4. Performance & Testing Review (>95% coverage)
5. Iterative Improvement Process (until perfect)
```

#### **Architecture Review**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Architecture Review Prompt"

VALIDATION CHECKLIST:
‚úÖ Service Layer: Result<T,E> + error boundaries + fallbacks
‚úÖ Component Layer: Accessibility + performance + state
‚úÖ Data Layer: Validation + sanitization + caching
‚úÖ Integration: WorkflowService + MockDataService

COMPLIANCE REQUIREMENTS:
- TypeScript: 100% coverage, no any types
- Security: Zero vulnerabilities, input validation
- Performance: Bundle < 500KB, LCP < 2.5s
```

#### **Code Quality Assessment**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Code Quality Deep Dive Prompt"

QUALITY METRICS:
- Cognitive Complexity: < 10 per function
- Function Length: < 50 lines
- Component Props: < 7 properties
- Dependency Count: < 15 per component

ASSESSMENT AREAS:
1. TypeScript Excellence (no any types)
2. React Best Practices (optimization)
3. Code Maintainability (DRY, SRP)
4. Error Handling Robustness
```

#### **Security & Accessibility Audit**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Security Assessment Prompt" + "Accessibility Compliance Prompt"

SECURITY REQUIREMENTS:
‚úÖ ALL inputs validated with Zod
‚úÖ ALL HTML sanitized with DOMPurify
‚úÖ NO sensitive data in logs
‚úÖ ALL APIs have error handling

ACCESSIBILITY REQUIREMENTS:
‚úÖ WCAG 2.1 AA compliance (100%)
‚úÖ Keyboard navigation complete
‚úÖ Screen reader compatibility
‚úÖ Color contrast 4.5:1 minimum
```

#### **Performance & Testing Excellence**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Performance Analysis Prompt" + "Testing Coverage Prompt"

PERFORMANCE STANDARDS:
- Bundle Size: < 500KB gzipped
- Time to Interactive: < 3 seconds
- Lighthouse Score: > 90
- Memory Usage: < 50MB baseline

TESTING STANDARDS:
- Unit Coverage: > 95%
- Integration Coverage: > 90%
- E2E Coverage: Critical paths
- Accessibility Testing: Integrated
```

#### **Iterative Improvement Process**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Improvement Iteration Prompt"

ITERATION PROTOCOL:
1. Validate previous issue resolution
2. Identify new issues from changes
3. Assess overall quality progression
4. Determine if additional iterations needed
5. Make approval/rejection decision

APPROVAL CRITERIA:
‚úÖ ALL critical issues resolved
‚úÖ NO new critical/high issues
‚úÖ Meets Microsoft enterprise standards
‚úÖ Overall score ‚â• 98%
```

#### **Final Approval Decision**

```
APPLY: docs/ai-instructions/specialized-prompts/microsoft-expert-review.md -> "Final Approval Prompt"

COMPREHENSIVE SCORECARD:
- Architecture: Must be 100
- Code Quality: Must be 100
- Security: Must be 100
- Accessibility: Must be 100
- Performance: Must be ‚â•90
- Testing: Must be ‚â•95

DECISION: ‚úÖ APPROVED / ‚ùå REJECTED
If REJECTED: Specify exact requirements for approval
```

---

## üìö **WORKFLOW REFERENCE**

### **Phase 1: Requirements & Planning**

```
1. ANALYZE requirements using workflow-instructions.md
2. APPLY core-standards.md principles
3. PLAN architecture with bulletproof patterns
4. DEFINE quality gates per quality-gates.md
5. SETUP context per context-management.md
```

### **Phase 2: Implementation**

```
1. IMPLEMENT services with specialized-prompts/code-generation.md
2. CREATE hooks following performance patterns
3. BUILD components with accessibility compliance
4. INTEGRATE with WorkflowService and MockDataService
5. VALIDATE against quality-gates.md continuously
```

### **Phase 3: Testing & Quality**

```
1. WRITE comprehensive tests per testing prompts
2. RUN accessibility audits (axe-core)
3. PERFORM performance profiling
4. VALIDATE security compliance
5. CHECK all quality gates pass
```

### **Phase 4: Refactoring & Optimization**

```
1. REFACTOR legacy code with refactoring prompts
2. OPTIMIZE performance with memoization patterns
3. ENHANCE accessibility compliance
4. DEBUG issues with specialized debugging prompts
5. MAINTAIN context per context-management strategies
```

---

## üéØ **QUALITY GATE QUICK CHECKS**

### **Pre-Commit (üî¥ CRITICAL)**

```bash
# TypeScript check
npx tsc --noEmit

# ESLint check
npx eslint . --max-warnings 0

# Unit tests
npm test -- --coverage

# Accessibility check
npx axe-cli http://localhost:3000

# Security scan
npm audit --audit-level high
```

### **Pre-PR (üü† HIGH)**

```bash
# Integration tests
npm run test:integration

# E2E tests
npm run test:e2e

# Performance audit
npx lighthouse-ci

# Bundle size check
npx bundlesize
```

### **Pre-Deployment (üî¥ CRITICAL)**

```bash
# Full test suite
npm run test:full

# Security penetration test
npm run security:pentest

# Load testing
npm run test:load

# Production readiness check
npm run deploy:validate
```

---

## üö® **EMERGENCY DEBUGGING**

### **Service Down**

```
1. APPLY debugging prompts for service errors
2. CHECK WorkflowService fallback execution
3. VERIFY MockDataService integration
4. VALIDATE error propagation path
5. IMPLEMENT immediate fallback
```

### **Performance Issues**

```
1. PROFILE component render performance
2. CHECK for memory leaks
3. ANALYZE bundle size impact
4. OPTIMIZE with memoization patterns
5. IMPLEMENT lazy loading
```

### **Accessibility Failures**

```
1. RUN axe-core audit immediately
2. CHECK keyboard navigation flow
3. VALIDATE screen reader compatibility
4. FIX ARIA attribute issues
5. TEST with real assistive technology
```

---

## üìñ **DOCUMENTATION QUICK ACCESS**

- **Core Standards**: `docs/ai-instructions/core-standards.md`
- **Workflow Process**: `docs/ai-instructions/workflow-instructions.md`
- **Code Templates**: `docs/ai-instructions/specialized-prompts/code-generation.md`
- **Refactoring Guide**: `docs/ai-instructions/specialized-prompts/refactoring-debugging.md`
- **Quality Gates**: `docs/ai-instructions/quality-gates.md`
- **Context Management**: `docs/ai-instructions/context-management.md`

---

## üé™ **PROMPT USAGE EXAMPLES**

### **Example 1: New Feature Request**

```
User: "Add user profile management functionality"

AI Response:
1. Loading core-standards.md for bulletproof patterns
2. Applying workflow-instructions.md Phase 1 analysis
3. Planning service-hook-component architecture
4. Using code-generation.md service template
5. Implementing with Result<T,E> pattern
6. Adding MockDataService fallbacks
7. Ensuring WCAG 2.1 AA compliance
8. Targeting 95% test coverage
```

### **Example 2: Performance Issue**

```
User: "Component is rendering slowly"

AI Response:
1. Applying refactoring-debugging.md performance optimization
2. Profiling render cycles and memory usage
3. Implementing React optimization patterns
4. Adding memoization with useMemo/useCallback
5. Optimizing with virtualization if needed
6. Validating performance improvements
```

### **Example 3: Accessibility Problem**

```
User: "Screen reader can't navigate our form"

AI Response:
1. Loading refactoring-debugging.md accessibility refactoring
2. Running axe-core audit
3. Implementing proper ARIA labels
4. Adding keyboard navigation support
5. Ensuring form field associations
6. Testing with assistive technology
```

---

**APPLY THESE PROMPTS SYSTEMATICALLY FOR CONSISTENT, HIGH-QUALITY AI/ML DEVELOPMENT!** üöÄüéØ
